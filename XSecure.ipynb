{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzsvHqHo2P9O"
      },
      "source": [
        "# Malicious URL Detector (Training Phase + Testing Phase)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7lKmQj_2P9T"
      },
      "source": [
        "## Importing necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KVwFc1x5eG7",
        "outputId": "21d32111-c5ae-415f-ada7-d7ec0998911a"
      },
      "outputs": [],
      "source": [
        "#cd /content/drive/MyDrive/MaliciousUrlDetec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dchmn-5V2V2Q",
        "outputId": "70901b08-62ee-4a47-afc9-f9dad8ca3b5f"
      },
      "outputs": [],
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive') '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YEfVvLz2P9U"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pandas as pd \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pickle\n",
        "import joblib "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "k26nzIwx2P9V",
        "outputId": "23bc9273-0188-4f94-e559-93eebb9fddaa",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"dataset.csv\",encoding=\"latin1\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJZ--Gva2P9X",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "feature_names_df = ['having_IPhaving_IP_Address','URLURL_Length','having_At_Symbol','double_slash_redirecting','Prefix_Suffix','having_Sub_Domain','Domain_registeration_length','HTTPS_token','SFH','Submitting_to_email','Abnormal_URL','Redirect','age_of_domain','DNSRecord','web_traffic']\n",
        "x_df = df[feature_names_df]\n",
        "y_df = df['Result']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8QCurW2P9X"
      },
      "source": [
        "## Plotting Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "KjFsPgO76bey",
        "outputId": "597b021b-e0f3-403a-917d-4bcb0fcd1349"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "X = x_df    #independent columns\n",
        "y = y_df    #target column \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X,y)\n",
        "fig, ax = plt.subplots(figsize=(15,7),dpi=200)\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(15).plot(kind='barh')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atN2hY802P9Z",
        "outputId": "f05d7cca-7f1e-4551-c521-f93b8f9ed06a"
      },
      "outputs": [],
      "source": [
        "x_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6d5-E402P9Z"
      },
      "source": [
        "## Applying train test split on data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TilUOwCe2P9a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.1,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "2KnOoc7r2P9b",
        "outputId": "851c5a6b-2d3a-4a6d-ca00-f016f58b8938"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U3MU8G52P9j"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Inu4K932P9k",
        "outputId": "af3f3cc2-7a37-42ea-eb54-de80696bc3bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=100)\n",
        "model.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSM7D5_P2P9l",
        "outputId": "4ba17e85-8c8c-468e-91b0-a931568a2153"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(y_test)\n",
        "    y_test = lb.transform(y_test)\n",
        "    y_pred = lb.transform(y_pred)\n",
        "    return roc_auc_score(y_test, y_pred, average=average)\n",
        "\n",
        "# Predict the transformed test documents\n",
        "predictions = model.predict((X_test))\n",
        "print(\"eh\",predictions)\n",
        "print('AUC: ', multiclass_roc_auc_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ-ECcaE-87k"
      },
      "source": [
        "**MIne bold text ! **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "8mk_HBca7Ow1",
        "outputId": "c4f3aa32-3897-4a21-c9fa-de05c5037fea"
      },
      "outputs": [],
      "source": [
        "#print('accuracy %s' % accuracy_score(predictions, y_test))\n",
        "bc=classification_report(y_test, predictions,target_names=['1','-1'])\n",
        "abc=confusion_matrix(y_test, predictions)\n",
        "#print(bc)\n",
        "#print(abc)\n",
        "generate_report(abc, multiclass_roc_auc_score(y_test, predictions), bc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpsbcbuj8e7J"
      },
      "source": [
        " Generate Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG4VabDE8eRN",
        "outputId": "89532a59-ade9-4ab2-e518-e003118b4bd0"
      },
      "outputs": [],
      "source": [
        "# Define report generator\n",
        "\n",
        "def generate_report(cmatrix, score, creport):\n",
        "  \"\"\"Generates and displays graphical reports\n",
        "  Keyword arguments:\n",
        "    cmatrix - Confusion matrix generated by the model\n",
        "    score --- Score generated by the model\n",
        "    creport - Classification Report generated by the model\n",
        "    \n",
        "  :Returns -- N/A\n",
        "  \"\"\"\n",
        "  \n",
        "  # Transform cmatrix because Sklearn has pred as columns and actual as rows.\n",
        "  cmatrix = cmatrix.T\n",
        "  \n",
        "  # Generate confusion matrix heatmap\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(cmatrix, \n",
        "              annot=True, \n",
        "              fmt=\"d\", \n",
        "              linewidths=.5, \n",
        "              square = True, \n",
        "              cmap = 'Blues', \n",
        "              annot_kws={\"size\": 16}, \n",
        "              xticklabels=['bad', 'good'],\n",
        "              yticklabels=['bad', 'good'])\n",
        "\n",
        "  plt.xticks(rotation='horizontal', fontsize=16)\n",
        "  plt.yticks(rotation='horizontal', fontsize=16)\n",
        "  plt.xlabel('Actual Label', size=20);\n",
        "  plt.ylabel('Predicted Label', size=20);\n",
        "\n",
        "  title = 'Accuracy Score: {0:.4f}'.format(score)\n",
        "  plt.title(title, size = 20);\n",
        "\n",
        "  # Display classification report and confusion matrix\n",
        "  print(creport)\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "print(\"\\n### Report Generator Defined ###\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JPaasv82P9q"
      },
      "source": [
        "## RandomForest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH5lyThX2P9r",
        "outputId": "ecccfaf1-2ecf-4e3c-e852-88e1147c4f78"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model=RandomForestClassifier(n_estimators=400,criterion='entropy')\n",
        "model.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIA2Q4Hz2P9r"
      },
      "source": [
        "## ROC score of RandomForest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vXDE8iV2P9r",
        "outputId": "cd5110c8-3560-483a-85ba-85b165371e60"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "predictions = model.predict((X_test))\n",
        "\n",
        "print('AUC: ', roc_auc_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhE3Oynl2P9s",
        "outputId": "49603a97-0a51-4220-bb7e-d301b85806cb"
      },
      "outputs": [],
      "source": [
        "model.score(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_WP1CTJ2P9s",
        "outputId": "e6ad0bf8-8c44-43c1-d819-b6a410f169ac"
      },
      "outputs": [],
      "source": [
        "print('accuracy %s' % accuracy_score(predictions, y_test))\n",
        "print(classification_report(y_test, predictions,target_names=['1','-1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "XqQzyiwpQvUW",
        "outputId": "81da6c25-07ec-4d17-bbc8-7c08f69bc426"
      },
      "outputs": [],
      "source": [
        "#print('accuracy %s' % accuracy_score(predictions, y_test))\n",
        "bc=classification_report(y_test, predictions,target_names=['1','-1'])\n",
        "abc=confusion_matrix(y_test, predictions)\n",
        "#print(bc)\n",
        "#print(abc)\n",
        "generate_report(abc, multiclass_roc_auc_score(y_test, predictions), bc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlkb8hr-2P9t"
      },
      "source": [
        "Variation of Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxfQsVWJ2P91",
        "outputId": "456c56ff-bd81-47fe-c7e4-0635d50efc29"
      },
      "outputs": [],
      "source": [
        "acc_ran_train=[]\n",
        "for i in range(9):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, train_size=(i+1)/10, random_state = 42)\n",
        "\n",
        "    ran = RandomForestClassifier(n_estimators=400,criterion='entropy')\n",
        "    ran.fit(X_train,y_train)\n",
        "    y_pred = ran.predict(X_test)\n",
        "    acc_ran_train.append(accuracy_score(y_pred, y_test))\n",
        "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print (acc_ran_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dJbCG4S2P92"
      },
      "source": [
        "Variation of Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcAEfc6y2P92",
        "outputId": "29d080f7-7415-4349-ce72-4436cdcc68c4"
      },
      "outputs": [],
      "source": [
        "acc_ran_test=[]\n",
        "for i in range(9):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=(i+1)/10, random_state = 42)\n",
        "\n",
        "    ran = RandomForestClassifier(n_estimators=400,criterion='entropy')\n",
        "    ran.fit(X_train,y_train)\n",
        "    y_pred = ran.predict(X_test)\n",
        "    acc_ran_test.append(accuracy_score(y_pred, y_test))\n",
        "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print (acc_ran_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo6czwDJ2P9-",
        "outputId": "6c82d616-e14b-40b3-8b1b-f0d33ebd3def"
      },
      "outputs": [],
      "source": [
        "l=model.predict([[1,1,1,1,-1,1,1,-1,1,-1,1,-1,-1,-1,-1]])\n",
        "l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5Xi4jkw2P9_",
        "outputId": "63b622b1-d3b3-4937-d590-638d862f035e"
      },
      "outputs": [],
      "source": [
        "l[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCrOVVv12P9_"
      },
      "source": [
        "## Pickling the model for use in Web Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzpfH9h-2P9_",
        "outputId": "2faf72fb-505c-4503-86c4-465ecac8716d"
      },
      "outputs": [],
      "source": [
        "filename = 'phish_trainedv9mud0.001.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        "print(\"Model has been Dumped in sav format File\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x5MwKz82P9_"
      },
      "source": [
        "## Feature Extraction Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xic3scBV2P9_",
        "outputId": "9ff62109-63ab-45be-f66a-5b86dd1122c4"
      },
      "outputs": [],
      "source": [
        "import whois\n",
        "import datetime\n",
        "text=input()\n",
        "aburl=-1\n",
        "digits=\"0123456789\"\n",
        "if text[8] in digits:\n",
        "    oneval=-1\n",
        "else:\n",
        "    oneval=1    \n",
        "if len(text)>170:\n",
        "    secval=-1\n",
        "else:\n",
        "    secval=1  \n",
        "if \"@\" in text:\n",
        "    thirdval=-1\n",
        "else:\n",
        "    thirdval=1    \n",
        "k=text.count(\"//\")          \n",
        "if k>1:\n",
        "    fourthval=-1\n",
        "else:\n",
        "    fourthval=1  \n",
        "if \"-\" in text:\n",
        "    fifthval=-1\n",
        "else:\n",
        "    fifthval=1         \n",
        "if \"https\" in text:\n",
        "    sixthval=1\n",
        "else:\n",
        "    sixthval=-1\n",
        "#subdomain ignored    \n",
        "\n",
        "temp=text\n",
        "temp=temp[6:]\n",
        "k1=temp.count(\"https\")\n",
        "\n",
        "if k1 >=1:\n",
        "    seventhval=-1\n",
        "else:\n",
        "    seventhval=1\n",
        "if \"about:blank\" in text:\n",
        "    eighthval=-1\n",
        "else:\n",
        "    eighthval=1\n",
        "if \"mail()\" or \"mailto:\" in text:\n",
        "    ninthval=-1\n",
        "else:\n",
        "    ninthval=1\n",
        "re=text.count(\"//\")          \n",
        "if re>3:\n",
        "    tenthval=-1\n",
        "else:\n",
        "    tenthval=1    \n",
        "\n",
        "import whois\n",
        "from datetime import datetime\n",
        "\n",
        "url=text\n",
        "\n",
        "try:\n",
        "    res=whois.whois(url)\n",
        "    print (res)\n",
        "    #print (len(res['creation_date']))\n",
        "    try:\n",
        "        a=res['creation_date'][0]\n",
        "        b=datetime.now()\n",
        "        c=b-a\n",
        "        d=c.days\n",
        "    except:\n",
        "        a=res['creation_date']\n",
        "        b=datetime.now()\n",
        "        c=b-a\n",
        "        d=c.days\n",
        "    #print (d)\n",
        "    if d>365:\n",
        "        eleventhval=1\n",
        "    else:\n",
        "        eleventhval=-1\n",
        "except:\n",
        "    aburl=1\n",
        "    eleventhval=-1   \n",
        "\n",
        "if aburl==1:\n",
        "    twelthval=-1\n",
        "else:\n",
        "    twelthval=1    \n",
        "    \n",
        "import urllib.request, sys, re\n",
        "import xmltodict, json\n",
        "\n",
        "try:\n",
        "    xml = urllib.request.urlopen('http://data.alexa.com/data?cli=10&dat=s&url={}'.format(text)).read()\n",
        "\n",
        "    result= xmltodict.parse(xml)\n",
        "\n",
        "    data = json.dumps(result).replace(\"@\",\"\")\n",
        "    data_tojson = json.loads(data)\n",
        "    url = data_tojson[\"ALEXA\"][\"SD\"][1][\"POPULARITY\"][\"URL\"]\n",
        "    rank= int(data_tojson[\"ALEXA\"][\"SD\"][1][\"POPULARITY\"][\"TEXT\"])\n",
        "    print (rank)\n",
        "    if rank<=100000:\n",
        "        thirt=1\n",
        "    else:\n",
        "        thirt=-1\n",
        "    print (thirt)    \n",
        "except:\n",
        "    thirt=-1\n",
        "    print (thirt)\n",
        "    \n",
        "print(\"site {site}, rank {rank}\".format(site=url,rank=rank))    \n",
        "\n",
        "\n",
        "print (oneval) #having ip   \n",
        "print (secval) #length\n",
        "print (thirdval) #atvalue\n",
        "print (fourthval) #double slash\n",
        "print (fifthval) #prefix suffix\n",
        "#print (sixthval) #ssl\n",
        "print (seventhval) #https token\n",
        "print (eighthval) #sfh\n",
        "print (ninthval) #submit to mail\n",
        "print (tenthval) #redirect\n",
        "print (eleventhval) #age of domain\n",
        "print (twelthval) #abnormal url\n",
        "print (thirt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBTlTgYo2P-A",
        "outputId": "f19862b2-341a-4e39-9895-b3386c8af915"
      },
      "outputs": [],
      "source": [
        "import whois\n",
        "import datetime\n",
        "text=input()\n",
        "aburl=-1\n",
        "digits=\"0123456789\"\n",
        "if text[8] in digits:\n",
        "    oneval=-1\n",
        "else:\n",
        "    oneval=1    \n",
        "if len(text)>170:\n",
        "    secval=-1\n",
        "else:\n",
        "    secval=1  \n",
        "if \"@\" in text:\n",
        "    thirdval=-1\n",
        "else:\n",
        "    thirdval=1    \n",
        "k=text.count(\"//\")          \n",
        "if k>1:\n",
        "    fourthval=-1\n",
        "else:\n",
        "    fourthval=1  \n",
        "if \"-\" in text:\n",
        "    fifthval=-1\n",
        "else:\n",
        "    fifthval=1         \n",
        "if \"https\" in text:\n",
        "    sixthval=1\n",
        "else:\n",
        "    sixthval=-1\n",
        "#subdomain ignored    \n",
        "\n",
        "temp=text\n",
        "temp=temp[6:]\n",
        "k1=temp.count(\"https\")\n",
        "\n",
        "if k1 >=1:\n",
        "    seventhval=-1\n",
        "else:\n",
        "    seventhval=1\n",
        "if \"about:blank\" in text:\n",
        "    eighthval=-1\n",
        "else:\n",
        "    eighthval=1\n",
        "if \"mail()\" or \"mailto:\" in text:\n",
        "    ninthval=-1\n",
        "else:\n",
        "    ninthval=1\n",
        "re=text.count(\"//\")          \n",
        "if re>3:\n",
        "    tenthval=-1\n",
        "else:\n",
        "    tenthval=1    \n",
        "\n",
        "import whois\n",
        "from datetime import datetime\n",
        "\n",
        "url=text\n",
        "\n",
        "try:\n",
        "    res=whois.whois(url)\n",
        "    print (res)\n",
        "    #print (len(res['creation_date']))\n",
        "    try:\n",
        "        a=res['creation_date'][0]\n",
        "        b=datetime.now()\n",
        "        c=b-a\n",
        "        d=c.days\n",
        "    except:\n",
        "        a=res['creation_date']\n",
        "        b=datetime.now()\n",
        "        c=b-a\n",
        "        d=c.days\n",
        "    #print (d)\n",
        "    if d>365:\n",
        "        eleventhval=1\n",
        "    else:\n",
        "        eleventhval=-1\n",
        "except:\n",
        "    aburl=1\n",
        "    eleventhval=-1   \n",
        "\n",
        "if aburl==1:\n",
        "    twelthval=-1\n",
        "else:\n",
        "    twelthval=1    \n",
        "    \n",
        "import urllib.request, sys, re\n",
        "import xmltodict, json\n",
        "\n",
        "try:\n",
        "    xml = urllib.request.urlopen('http://data.alexa.com/data?cli=10&dat=s&url={}'.format(text)).read()\n",
        "\n",
        "    result= xmltodict.parse(xml)\n",
        "\n",
        "    data = json.dumps(result).replace(\"@\",\"\")\n",
        "    data_tojson = json.loads(data)\n",
        "    url = data_tojson[\"ALEXA\"][\"SD\"][1][\"POPULARITY\"][\"URL\"]\n",
        "    rank= int(data_tojson[\"ALEXA\"][\"SD\"][1][\"POPULARITY\"][\"TEXT\"])\n",
        "    print (rank)\n",
        "    if rank<=100000:\n",
        "        thirt=1\n",
        "    else:\n",
        "        thirt=-1\n",
        "    print (thirt)    \n",
        "except:\n",
        "    thirt=-1\n",
        "    print (thirt)\n",
        "    \n",
        "print(\"site {site}, rank {rank}\".format(site=url,rank=rank))    \n",
        "\n",
        "\n",
        "print (oneval) #having ip   \n",
        "print (secval) #length\n",
        "print (thirdval) #atvalue\n",
        "print (fourthval) #double slash\n",
        "print (fifthval) #prefix suffix\n",
        "#print (sixthval) #ssl\n",
        "print (seventhval) #https token\n",
        "print (eighthval) #sfh\n",
        "print (ninthval) #submit to mail\n",
        "print (tenthval) #redirect\n",
        "print (eleventhval) #age of domain\n",
        "print (twelthval) #abnormal url\n",
        "print (thirt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7cxf2Ao2P-B",
        "outputId": "7af4f48e-5ecd-405e-f4fd-8732fcd3cee9"
      },
      "outputs": [],
      "source": [
        "model.predict([[-1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1]])\n",
        "model.predict([[1, -1, 1, 1,  1, -1,  1, 1, 1, -1,  1, 1,  1, 1, -1]])\n",
        "model.predict([[1, -1, 1, 1, -1, -1,  1, 1, 1, -1,  1, 1,  1, 1, -1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nqfi51o2P-B",
        "outputId": "be9415b5-b31f-4558-d6ac-4653d6194453"
      },
      "outputs": [],
      "source": [
        "import whois\n",
        "import datetime\n",
        "text=input()\n",
        "aburl=-1\n",
        "digits=\"0123456789\"\n",
        "if text[8] in digits:\n",
        "    oneval=-1\n",
        "else:\n",
        "    oneval=1    \n",
        "if len(text)>170:\n",
        "    secval=-1\n",
        "else:\n",
        "    secval=1  \n",
        "if \"@\" in text:\n",
        "    thirdval=-1\n",
        "else:\n",
        "    thirdval=1    \n",
        "k=text.count(\"//\")          \n",
        "if k>1:\n",
        "    fourthval=-1\n",
        "else:\n",
        "    fourthval=1  \n",
        "if \"-\" in text:\n",
        "    fifthval=-1\n",
        "else:\n",
        "    fifthval=1         \n",
        "if \"https\" in text:\n",
        "    sixthval=1\n",
        "else:\n",
        "    sixthval=-1\n",
        "#subdomain ignored    \n",
        "\n",
        "temp=text\n",
        "temp=temp[6:]\n",
        "k1=temp.count(\"https\")\n",
        "\n",
        "if k1 >=1:\n",
        "    seventhval=-1\n",
        "else:\n",
        "    seventhval=1\n",
        "if \"about:blank\" in text:\n",
        "    eighthval=-1\n",
        "else:\n",
        "    eighthval=1\n",
        "if \"mail()\" or \"mailto:\" in text:\n",
        "    ninthval=-1\n",
        "else:\n",
        "    ninthval=1\n",
        "re=text.count(\"//\")          \n",
        "if re>3:\n",
        "    tenthval=-1\n",
        "else:\n",
        "    tenthval=1    \n",
        "\n",
        "import whois\n",
        "from datetime import datetime\n",
        "\n",
        "url=text\n",
        "\n",
        "try:\n",
        "    res=whois.whois(url)\n",
        "    print (res)\n",
        "    #print (len(res['creation_date']))\n",
        "    try:\n",
        "        a=res['creation_date'][0]\n",
        "        b=datetime.now()\n",
        "        c=b-a\n",
        "        d=c.days\n",
        "    except:\n",
        "        a=res['creation_date']\n",
        "        b=datetime.now()\n",
        "        c=b-a\n",
        "        d=c.days\n",
        "    #print (d)\n",
        "    if d>365:\n",
        "        eleventhval=1\n",
        "    else:\n",
        "        eleventhval=-1\n",
        "except:\n",
        "    aburl=1\n",
        "    eleventhval=-1   \n",
        "\n",
        "if aburl==1:\n",
        "    twelthval=-1\n",
        "else:\n",
        "    twelthval=1    \n",
        "\n",
        "\n",
        "print (oneval) #having ip   \n",
        "print (secval) #length\n",
        "print (thirdval) #atvalue\n",
        "print (fourthval) #double slash\n",
        "print (fifthval) #prefix suffix\n",
        "print (sixthval) #ssl\n",
        "print (seventhval) #https token\n",
        "print (eighthval) #sfh\n",
        "print (ninthval) #submit to mail\n",
        "print (tenthval) #redirect\n",
        "print (eleventhval) #age of domain\n",
        "print (twelthval) #abnormal url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohpen_v52P-B"
      },
      "source": [
        "## Pickled model is used in below step :\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh7C2VBs2P-B"
      },
      "source": [
        "## Module to predict whether a URL is Legitimate or Malicious (Phishing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFf_1Mvfj3dN",
        "outputId": "6003741f-f0bb-4b1d-8ac4-8992ca92bf68"
      },
      "outputs": [],
      "source": [
        "pip install json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "3rYZnT6F2P-C",
        "outputId": "4ec2b614-e800-41a0-fa0c-2fb613656296"
      },
      "outputs": [],
      "source": [
        "text=input()\n",
        "#nm=request.GET['url']\n",
        "import tldextract\n",
        "do=tldextract.extract(text).domain\n",
        "sdo=tldextract.extract(text).subdomain\n",
        "suf=tldextract.extract(text).suffix\n",
        "aburl=-1\n",
        "digits=\"0123456789\"\n",
        "if text[8] in digits:\n",
        "    oneval=-1\n",
        "else:\n",
        "    oneval=1    \n",
        "if len(text)>170:\n",
        "    secval=-1\n",
        "else:\n",
        "    secval=1  \n",
        "if \"@\" in text:\n",
        "    thirdval=-1\n",
        "    var3=\"'@' detected\"\n",
        "else:\n",
        "    thirdval=1       \n",
        "    var3=\"No '@' detected\"\n",
        "k=text.count(\"//\")          \n",
        "if k>1:\n",
        "    fourthval=-1\n",
        "    var4=\"More Redirects\"\n",
        "else:\n",
        "    fourthval=1\n",
        "\n",
        "if \"-\" in do or \"-\" in sdo:\n",
        "    fifthval=-1\n",
        "    var5=\"Prefix-Suffix detected\"\n",
        "else:\n",
        "    fifthval=1 \n",
        "    var5=\"No Prefix-Suffix detected\"     \n",
        "\n",
        "if \"https\" in text:\n",
        "    sixthval=1\n",
        "else:\n",
        "    sixthval=-1\n",
        "temp=text\n",
        "temp=temp[6:]\n",
        "k1=temp.count(\"https\")\n",
        "\n",
        "if k1 >=1:\n",
        "    seventhval=-1\n",
        "else:\n",
        "    seventhval=1\n",
        "if \"about:blank\" in text:\n",
        "    eighthval=-1\n",
        "else:\n",
        "    eighthval=1\n",
        "if \"mail()\" or \"mailto:\" in text:\n",
        "    ninthval=-1\n",
        "else:\n",
        "    ninthval=1\n",
        "re=text.count(\"//\")          \n",
        "if re>3:\n",
        "    tenthval=-1\n",
        "    var10=\"redirects more than 2\"\n",
        "else:\n",
        "    tenthval=1    \n",
        "    var10=f\"{re-1} redirects detected\"\n",
        "\n",
        "import whois\n",
        "from datetime import datetime\n",
        "\n",
        "url=text\n",
        "#code replaced whois\n",
        "# \n",
        "\"\"\"try:\"\"\"\n",
        "d=-1\n",
        "try:\n",
        "    res=whois.whois(url)\n",
        "    cpyres=res\n",
        "except:\n",
        "    print(\"getaddrerrror DNE\")\n",
        "    d=0\n",
        "    name=\"Not found in WHOIS database\"\n",
        "    org=\"Not found in WHOIS database\"\n",
        "    add=\"Not found in WHOIS database\"\n",
        "    city=\"Not found in WHOIS database\"\n",
        "    state=\"Not found in WHOIS database\"\n",
        "    ziip=\"Not found in WHOIS database\"\n",
        "    country=\"Not found in WHOIS database\"\n",
        "    emails=\"Not found in WHOIS database\"\n",
        "    dom=\"Not Found in WHOIS database\"\n",
        "    registrar=\"Not Found in WHOIS database\"\n",
        "if d!=0:    \n",
        "    try:\n",
        "        if len(res.creation_date)>1:\n",
        "            a=res['creation_date'][0]\n",
        "            b=datetime.now()\n",
        "            c=b-a\n",
        "            d=c.days\n",
        "    except:\n",
        "        a=res['creation_date']\n",
        "        b=datetime.now()\n",
        "        c=b-a\n",
        "        d=c.days\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if d>365:\n",
        "    eleventhval=1\n",
        "    aburl=1\n",
        "    var11=f\"Domain age is {d} days\"\n",
        "elif d<=365:\n",
        "    eleventhval=-1\n",
        "    aburl=-1\n",
        "    var11=f\"Domain age working less than a year, {d} days\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if aburl==-1:\n",
        "    twelthval=-1\n",
        "    varab=\"Abnormal URL detected\"\n",
        "else:\n",
        "    twelthval=1 \n",
        "    varab=\"Website Registered on WHOIS Database\"\n",
        "\n",
        "#print (twelthval,eleventhval,aburl,d)    \n",
        "import urllib.request, sys, re\n",
        "import xmltodict, json\n",
        "\n",
        "try:\n",
        "    xml = urllib.request.urlopen('http://data.alexa.com/data?cli=10&dat=s&url={}'.format(text)).read()\n",
        "\n",
        "    result= xmltodict.parse(xml)\n",
        "\n",
        "    data = json.dumps(result).replace(\"@\",\"\")\n",
        "    data_tojson = json.loads(data)\n",
        "    url = data_tojson[\"ALEXA\"][\"SD\"][1][\"POPULARITY\"][\"URL\"]\n",
        "    rank= int(data_tojson[\"ALEXA\"][\"SD\"][1][\"POPULARITY\"][\"TEXT\"])\n",
        "    #print (\"rank\",rank)\n",
        "    if rank<=150000:\n",
        "        thirt=1\n",
        "    else:\n",
        "        thirt=-1\n",
        "        var13=f\"Ranked {rank} in Alexa Database, Larger index in alexa database detected!!\"\n",
        "    #print (thirt)    \n",
        "except:\n",
        "    thirt=-1 \n",
        "    rank=-1\n",
        "    ##############var13=\"Larger index in alexa database\"\n",
        "    var13=\"Not indexed in alexa database\"\n",
        "    #print (rank)                  \n",
        "\n",
        "\n",
        "\n",
        "filename = 'phish_trainedv7mud0.001.sav'\n",
        "\n",
        "loaded_model = joblib.load(filename)\n",
        "\n",
        "arg=loaded_model.predict(([[oneval,secval,thirdval,fourthval,fifthval,seventhval,eighthval,ninthval,tenthval,eleventhval,twelthval,thirt]]))\n",
        "arg"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "XSecure.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
